{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'preprocessing'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m image_scaling, convert_image, label_conversion\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfood_classifier\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FoodDataset\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'preprocessing'"
     ]
    }
   ],
   "source": [
    "from preprocessing.preprocessing import image_scaling, convert_image, label_conversion\n",
    "from model.food_classifier import FoodDataset\n",
    "import torch\n",
    "import torchinfo\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "import json\n",
    "import gc\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import timm\n",
    "import pandas as pd\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = 'images'\n",
    "data_folder = 'data'\n",
    "BATCH_SIZE = 32\n",
    "# Load calorie database (for food labels)\n",
    "CALORIE_DB_FILE = os.path.join(data_folder, \"calories_database.json\")\n",
    "with open(CALORIE_DB_FILE, \"r\") as f:\n",
    "    calorie_db = json.load(f)\n",
    "\n",
    "FOOD_LABELS = sorted(list(calorie_db.keys()))\n",
    "NUM_CLASSES = len(FOOD_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18 = timm.create_model('resnet18', pretrained=True, num_classes=NUM_CLASSES)\n",
    "resnet26 = timm.create_model('resnet26', pretrained=True, num_classes=NUM_CLASSES)\n",
    "resnet34 = timm.create_model('resnet34', pretrained=True, num_classes=NUM_CLASSES)\n",
    "resnet50 = timm.create_model('resnet50', pretrained=True, num_classes=NUM_CLASSES)\n",
    "# resnet101 = timm.create_model('resnet101', pretrained=True, num_classes=NUM_CLASSES)\n",
    "# resnet200 = timm.create_model('resnet200')#, pretrained=True)\n",
    "vittiny = timm.create_model('vit_tiny_patch16_384', pretrained=True, num_classes=NUM_CLASSES)\n",
    "vitsmall16 = timm.create_model('vit_small_patch16_384', pretrained=True, num_classes=NUM_CLASSES)\n",
    "vitsmall32 = timm.create_model('vit_small_patch32_384', pretrained=True, num_classes=NUM_CLASSES)\n",
    "# vitlarge16 = timm.create_model('vit_large_patch16_384', pretrained=True, num_classes=NUM_CLASSES)\n",
    "# vitlarge32 = timm.create_model('vit_large_patch32_384', pretrained=True, num_classes=NUM_CLASSES)\n",
    "# vitbase16 = timm.create_model('vit_base_patch16_384', pretrained=True, num_classes=NUM_CLASSES)\n",
    "# vitbase32 = timm.create_model('vit_base_patch32_384', pretrained=True, num_classes=NUM_CLASSES)\n",
    "\n",
    "resnet_models = {\n",
    "    'ResNet18': resnet18,\n",
    "    'ResNet26': resnet26,\n",
    "    'ResNet34': resnet34,\n",
    "    'ResNet50': resnet50\n",
    "    # 'ResNet101': resnet101,\n",
    "    # 'ResNet200': resnet200\n",
    "}\n",
    "\n",
    "vit_models = {\n",
    "    'ViT-Tiny': vittiny,\n",
    "    'ViT-Small 16': vitsmall16,\n",
    "    'ViT-Small 32': vitsmall32\n",
    "    # 'ViT-Large 16' : vitlarge16,\n",
    "    # 'ViT-Large 32' : vitlarge32,\n",
    "    # 'ViT-Base 16': vitbase16,\n",
    "    # 'ViT-Base 32': vitbase32\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Data Transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((400, 400)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "transform384 = transforms.Compose([\n",
    "    transforms.Resize((384, 384)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Load Datasets\n",
    "train_dataset = FoodDataset(json_path=os.path.join(data_folder, \"train.json\"), \n",
    "                            img_dir=\"images_resized\",\n",
    "                            transform=transform)\n",
    "test_dataset = FoodDataset(json_path=os.path.join(data_folder, \"test.json\"), \n",
    "                          img_dir=\"images_resized\",\n",
    "                          transform=transform)\n",
    "train_dataset384 = FoodDataset(json_path=os.path.join(data_folder, \"train.json\"), \n",
    "                            img_dir=\"images_resized\",\n",
    "                            transform=transform384)\n",
    "test_dataset384 = FoodDataset(json_path=os.path.join(data_folder, \"test.json\"), \n",
    "                          img_dir=\"images_resized\",\n",
    "                          transform=transform384)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "train_loader384 = DataLoader(train_dataset384, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader384 = DataLoader(test_dataset384, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, trainloader, optimizer, criterion, device, epochs=10):\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0\n",
    "        model.train()\n",
    "        for images, labels in trainloader:\n",
    "            images, labels = images.to(device), labels.to(device).float()\n",
    "            optimizer.zero_grad()\n",
    "            out = model(images)\n",
    "            loss = criterion(out, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # delete from memory\n",
    "            del images\n",
    "            del labels\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "            \n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, testloader, device):\n",
    "    model.eval() # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            unit_step_activation = torch.where(outputs > 0, torch.ones_like(outputs), torch.zeros_like(outputs))\n",
    "            total += labels.numel()\n",
    "            correct += (unit_step_activation == labels).sum().item()\n",
    "\n",
    "            del images\n",
    "            del labels\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "    return 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model ResNet18\n",
      "Epoch 1/10, Loss: 4.943054974079132\n",
      "Epoch 2/10, Loss: 3.160201515470232\n",
      "Epoch 3/10, Loss: 2.448873622076852\n",
      "Epoch 4/10, Loss: 2.277694340263094\n",
      "Epoch 5/10, Loss: 2.1228376924991608\n",
      "Epoch 6/10, Loss: 2.045820278780801\n",
      "Epoch 7/10, Loss: 2.0365512328488484\n",
      "Epoch 8/10, Loss: 1.9809543873582567\n",
      "Epoch 9/10, Loss: 1.9895618898527963\n",
      "Epoch 10/10, Loss: 1.9710689868245805\n",
      "Training complete\n",
      "ResNet18 Test Accuracy: 88.77911079745942%\n",
      "Training model ResNet26\n",
      "Epoch 1/10, Loss: 3.5011992880276273\n",
      "Epoch 2/10, Loss: 2.5404027615274702\n",
      "Epoch 3/10, Loss: 2.3086078422410146\n",
      "Epoch 4/10, Loss: 2.2291954457759857\n",
      "Epoch 5/10, Loss: 2.1681939448629106\n",
      "Epoch 6/10, Loss: 2.0865977874823978\n",
      "Epoch 7/10, Loss: 2.1430258623191287\n",
      "Epoch 8/10, Loss: 2.116500062601907\n",
      "Epoch 9/10, Loss: 2.028761182512556\n",
      "Epoch 10/10, Loss: 2.039588817528316\n",
      "Training complete\n",
      "ResNet26 Test Accuracy: 90.0846859562456%\n",
      "Training model ResNet34\n",
      "Epoch 1/10, Loss: 5.191759475639889\n",
      "Epoch 2/10, Loss: 3.3474735617637634\n",
      "Epoch 3/10, Loss: 2.4940358698368073\n",
      "Epoch 4/10, Loss: 2.2117281769003188\n",
      "Epoch 5/10, Loss: 2.143218551363264\n",
      "Epoch 6/10, Loss: 2.0809450021811893\n",
      "Epoch 7/10, Loss: 2.066948630980083\n",
      "Epoch 8/10, Loss: 2.0320041605404446\n",
      "Epoch 9/10, Loss: 1.9927038422652654\n",
      "Epoch 10/10, Loss: 1.961474405867713\n",
      "Training complete\n",
      "ResNet34 Test Accuracy: 88.56739590684545%\n",
      "Training model ResNet50\n",
      "Epoch 1/10, Loss: 4.985526178564344\n",
      "Epoch 2/10, Loss: 3.1001163593360355\n",
      "Epoch 3/10, Loss: 2.3797970371586934\n",
      "Epoch 4/10, Loss: 2.169178926518985\n",
      "Epoch 5/10, Loss: 2.0834613910743167\n",
      "Epoch 6/10, Loss: 2.0365089688982283\n",
      "Epoch 7/10, Loss: 2.010918678981917\n",
      "Epoch 8/10, Loss: 2.039041776742254\n",
      "Epoch 9/10, Loss: 1.9454902453081948\n",
      "Epoch 10/10, Loss: 1.8748448427234377\n",
      "Training complete\n",
      "ResNet50 Test Accuracy: 92.44883556810163%\n",
      "Training model ViT-Tiny\n",
      "Epoch 1/10, Loss: 5.265922427177429\n",
      "Epoch 2/10, Loss: 3.058172051395689\n",
      "Epoch 3/10, Loss: 2.5841968655586243\n",
      "Epoch 4/10, Loss: 2.3888964653015137\n",
      "Epoch 5/10, Loss: 2.2158900839941844\n",
      "Epoch 6/10, Loss: 2.1395732206957683\n",
      "Epoch 7/10, Loss: 2.073819249868393\n",
      "Epoch 8/10, Loss: 2.1226095174040114\n",
      "Epoch 9/10, Loss: 2.061637137617384\n",
      "Epoch 10/10, Loss: 2.0783020683697293\n",
      "Training complete\n",
      "ViT-Tiny Test Accuracy: 65.70218772053634%\n",
      "Training model ViT-Small 16\n",
      "Epoch 1/10, Loss: 6.13359408719199\n",
      "Epoch 2/10, Loss: 5.010882488318852\n",
      "Epoch 3/10, Loss: 4.354730921132224\n",
      "Epoch 4/10, Loss: 4.028567356722696\n",
      "Epoch 5/10, Loss: 3.8398759961128235\n",
      "Epoch 6/10, Loss: 3.410104261977332\n",
      "Epoch 7/10, Loss: 3.2291557022503445\n",
      "Epoch 8/10, Loss: 2.892726148877825\n",
      "Epoch 9/10, Loss: 2.64235297696931\n",
      "Epoch 10/10, Loss: 2.5443924410002574\n",
      "Training complete\n",
      "ViT-Small 16 Test Accuracy: 69.4424841213832%\n",
      "Training model ViT-Small 32\n",
      "Epoch 1/10, Loss: 6.4867831979479105\n",
      "Epoch 2/10, Loss: 5.22781355040414\n",
      "Epoch 3/10, Loss: 4.632051042148045\n",
      "Epoch 4/10, Loss: 4.657278520720346\n",
      "Epoch 5/10, Loss: 4.519720690590995\n",
      "Epoch 6/10, Loss: 4.043371251651219\n",
      "Epoch 7/10, Loss: 3.8081745164734975\n",
      "Epoch 8/10, Loss: 3.4701426880700246\n",
      "Epoch 9/10, Loss: 3.222914823463985\n",
      "Epoch 10/10, Loss: 3.06112168942179\n",
      "Training complete\n",
      "ViT-Small 32 Test Accuracy: 65.31404375441073%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model name</th>\n",
       "      <th>test accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ResNet18</td>\n",
       "      <td>88.779111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ResNet26</td>\n",
       "      <td>90.084686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ResNet34</td>\n",
       "      <td>88.567396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ResNet50</td>\n",
       "      <td>92.448836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ViT-Tiny</td>\n",
       "      <td>65.702188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ViT-Small 16</td>\n",
       "      <td>69.442484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ViT-Small 32</td>\n",
       "      <td>65.314044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model name  test accuracy\n",
       "0      ResNet18      88.779111\n",
       "1      ResNet26      90.084686\n",
       "2      ResNet34      88.567396\n",
       "3      ResNet50      92.448836\n",
       "4      ViT-Tiny      65.702188\n",
       "5  ViT-Small 16      69.442484\n",
       "6  ViT-Small 32      65.314044"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for rn_model in resnet_models.keys():\n",
    "    model = resnet_models[rn_model].to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n",
    "    print(f\"Training model {rn_model}\")\n",
    "    train(model, train_loader, optimizer, criterion, device)\n",
    "    print(\"Training complete\")\n",
    "    accuracy = evaluate(model, test_loader, device)\n",
    "    print(f\"{rn_model} Test Accuracy: {accuracy}%\")\n",
    "    results.append({\n",
    "        'model name': rn_model,\n",
    "        'test accuracy': accuracy\n",
    "    })\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "for vit_model in vit_models.keys():\n",
    "    model = vit_models[vit_model].to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n",
    "    print(f\"Training model {vit_model}\")\n",
    "    train(model, train_loader384, optimizer, criterion, device)\n",
    "    print(\"Training complete\")\n",
    "    accuracy = evaluate(model, test_loader384, device)\n",
    "    print(f\"{vit_model} Test Accuracy: {accuracy}%\")\n",
    "    results.append({\n",
    "        'model name': vit_model,\n",
    "        'test accuracy': accuracy\n",
    "    })\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
